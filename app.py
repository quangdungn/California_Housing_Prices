import streamlit as st 
import pandas as pd
import numpy as np
import joblib

# 1. T·∫£i c√°c m√¥ h√¨nh ƒë√£ l∆∞u
models = {
    'Linear Regression': joblib.load('linear_regression_model.joblib'),
    'Ridge Regression': joblib.load('ridge_regression_model.joblib'),
    'Neural Network': joblib.load('mlp_regressor_model.joblib'),
    'Stacking Model': joblib.load('stacking_regressor_model.joblib')
}

# 2. ƒê·ªçc d·ªØ li·ªáu g·ªëc ƒë·ªÉ l·∫•y gi√° tr·ªã trung v·ªã cho c√°c c·ªôt s·ªë v√† l·∫•y danh s√°ch c√°c c·ªôt
data = pd.read_csv('housing.csv')

# L∆∞u danh s√°ch c√°c c·ªôt sau khi ƒë√£ th·ª±c hi·ªán get_dummies trong qu√° tr√¨nh hu·∫•n luy·ªán
data = data.dropna()
data = pd.get_dummies(data, columns=['ocean_proximity'])
feature_columns = data.drop('median_house_value', axis=1).columns.tolist()

# 3. L·∫•y danh s√°ch c√°c ƒë·∫∑c tr∆∞ng
numeric_features = [
    'longitude', 'latitude', 'housing_median_age', 'total_rooms',
    'total_bedrooms', 'population', 'households', 'median_income'
]
categorical_features = ['ocean_proximity']

# 4. T·∫°o giao di·ªán ng∆∞·ªùi d√πng
st.title('üè† D·ª± ƒëo√°n Gi√° nh√† California')

st.write('Nh·∫≠p th√¥ng tin b√™n d∆∞·ªõi ƒë·ªÉ d·ª± ƒëo√°n gi√° nh√†:')

# 5. T·∫°o c√°c input cho ng∆∞·ªùi d√πng
input_data = {}

# Nh·∫≠p c√°c ƒë·∫∑c tr∆∞ng s·ªë
for feature in numeric_features:
    input_value = st.text_input(f'Nh·∫≠p {feature}', '')
    input_data[feature] = input_value

# Nh·∫≠p ƒë·∫∑c tr∆∞ng ph√¢n lo·∫°i
input_data['ocean_proximity'] = st.selectbox(
    'Ch·ªçn ocean_proximity',
    options=data.columns[data.columns.str.startswith('ocean_proximity_')].str.replace('ocean_proximity_', ''),
    index=0
)

# L·ª±a ch·ªçn m√¥ h√¨nh
model_name = st.selectbox(
    'Ch·ªçn m√¥ h√¨nh ƒë·ªÉ d·ª± ƒëo√°n',
    options=list(models.keys()),
    index=3  # M·∫∑c ƒë·ªãnh ch·ªçn Stacking Model
)

# 6. Khi ng∆∞·ªùi d√πng nh·∫•n n√∫t 'D·ª± ƒëo√°n'
if st.button('D·ª± ƒëo√°n'):
    # Chuy·ªÉn ƒë·ªïi input_data th√†nh DataFrame
    input_df = pd.DataFrame([input_data])

    # X·ª≠ l√Ω c√°c √¥ kh√¥ng nh·∫≠p d·ªØ li·ªáu
    # Chuy·ªÉn c√°c gi√° tr·ªã s·ªë t·ª´ chu·ªói sang s·ªë th·ª±c
    for col in numeric_features:
        if input_df[col][0] == '':
            # S·ª≠ d·ª•ng gi√° tr·ªã trung v·ªã n·∫øu ng∆∞·ªùi d√πng kh√¥ng nh·∫≠p
            input_df[col] = data[col].median()
        else:
            try:
                input_df[col] = float(input_df[col][0])
            except ValueError:
                st.error(f'Gi√° tr·ªã nh·∫≠p v√†o cho {col} kh√¥ng h·ª£p l·ªá. Vui l√≤ng nh·∫≠p s·ªë.')
                st.stop()

    # One-hot encoding cho 'ocean_proximity'
    ocean_proximity_dummies = pd.get_dummies(input_df['ocean_proximity'], prefix='ocean_proximity')
    input_df = pd.concat([input_df[numeric_features], ocean_proximity_dummies], axis=1)

    # ƒê·∫£m b·∫£o r·∫±ng c√°c c·ªôt trong input_df kh·ªõp v·ªõi c√°c c·ªôt trong qu√° tr√¨nh hu·∫•n luy·ªán
    for col in feature_columns:
        if col not in input_df.columns:
            input_df[col] = 0  # Th√™m c·ªôt thi·∫øu v·ªõi gi√° tr·ªã 0

    input_df = input_df[feature_columns]  # S·∫Øp x·∫øp l·∫°i th·ª© t·ª± c√°c c·ªôt

    # L·∫•y m√¥ h√¨nh ƒë∆∞·ª£c ch·ªçn
    selected_model = models[model_name]

    # D·ª± ƒëo√°n
    prediction = selected_model.predict(input_df)[0]

    # Hi·ªÉn th·ªã k·∫øt qu·∫£
    st.success(f'M√¥ h√¨nh s·ª≠ d·ª•ng: **{model_name}**')
    st.success(f'Gi√° nh√† d·ª± ƒëo√°n: **${prediction:,.2f}**')
